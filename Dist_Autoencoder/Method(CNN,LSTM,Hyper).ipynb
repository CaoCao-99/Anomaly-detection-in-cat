{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Model ,models, layers, optimizers, regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping,LambdaCallback\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from contextlib import redirect_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        loaded_data = pickle.load(file)\n",
    "    return loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dist = load_data('/home/sm32289/Cat_Pose/AutoEncoder/Model2/Data/2/Normal/dist.pkl')\n",
    "normal_label = [0] * normal_dist.shape[0]\n",
    "\n",
    "abnormal_dist = load_data('/home/sm32289/Cat_Pose/AutoEncoder/Model2/Data/2/Abnormal/dist.pkl')\n",
    "abnormal_label = [1] * abnormal_dist.shape[0]\n",
    "#y = to_categorical(labels).astype(int)\n",
    "# Split into train, valid, and test \n",
    "x_train, x_test, y_train, y_test = train_test_split(normal_dist, normal_label, test_size=0.1)\n",
    "\n",
    "x_valid, xx_test, y_valid, yy_test = train_test_split(abnormal_dist, abnormal_label, test_size=0.8)\n",
    "x_test = np.concatenate([x_test, xx_test])\n",
    "y_test = np.concatenate([y_test, yy_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "class CNNAutoencoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CNNAutoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Reshape((40, 15, 15, 1), input_shape=(40, 15, 15)),\n",
    "            layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling3D((2, 2, 2), padding='same'),\n",
    "            layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling3D((2, 2, 2), padding='same'),\n",
    "        ])\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same'),\n",
    "            layers.UpSampling3D((2, 2, 2)),\n",
    "            layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same'),\n",
    "            layers.UpSampling3D((2, 2, 2)),\n",
    "            layers.Conv3D(1, (3, 3, 3), activation='sigmoid', padding='same'),\n",
    "            layers.Cropping3D(((0, 1), (0, 0), (0, 0)))\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Create an instance of the CNNAutoencoder model\n",
    "autoencoder_cnn = CNNAutoencoder()\n",
    "\n",
    "# Display the model summary\n",
    "autoencoder_cnn.build((None, 40, 15, 15))\n",
    "autoencoder_cnn.summary()\n",
    "\n",
    "autoencoder_cnn.compile(optimizer=Adam(), loss=MeanSquaredError())\n",
    "\n",
    "\n",
    "# 학습\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "autoencoder_cnn.fit(x_train, x_train, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "input_shape = (40, 15, 15)\n",
    "x_train = x_train.reshape((-1, input_shape[0], input_shape[1] * input_shape[2]))\n",
    "\n",
    "# 모델 구성\n",
    "latent_dim = 128  # LSTM 유닛 수 (압축된 표현의 차원)\n",
    "inputs = Input(shape=(input_shape[0], input_shape[1] * input_shape[2]))\n",
    "encoded = LSTM(latent_dim, activation='relu')(inputs)\n",
    "\n",
    "decoded = RepeatVector(input_shape[0])(encoded)\n",
    "decoded = LSTM(input_shape[1] * input_shape[2], activation='relu', return_sequences=True)(decoded)\n",
    "\n",
    "autoencoder = Model(inputs, decoded)\n",
    "\n",
    "# 컴파일\n",
    "autoencoder.compile(optimizer=Adam(), loss=MeanSquaredError())\n",
    "\n",
    "# 훈련\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "autoencoder.fit(x_train, x_train, batch_size=batch_size, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM+CNN autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dynamic_lstmcnn_auto_encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_18 (Sequential)  (None, 160, 128)          155072    \n",
      "                                                                 \n",
      " sequential_19 (Sequential)  (None, None, 16, 16, 1)   216257    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 371329 (1.42 MB)\n",
      "Trainable params: 371329 (1.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, Input\n",
    "class DynamicLSTMCNNAutoEncoder(models.Model):\n",
    "    def __init__(self):\n",
    "        super(DynamicLSTMCNNAutoEncoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = models.Sequential([\n",
    "            layers.Reshape((-1, 1)),  # Flatten the input\n",
    "            layers.Reshape((40, 15, 15, 1)),  # Reshape according to the input shape\n",
    "            layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling3D((2, 2, 2), padding='same'),\n",
    "            layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling3D((2, 2, 2), padding='same'),\n",
    "            layers.Reshape((-1, 64)),  # Flatten the output of Conv3D\n",
    "            layers.LSTM(128, activation='relu', return_sequences=True)\n",
    "        ])\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = models.Sequential([\n",
    "            layers.LSTM(64, activation='relu', return_sequences=True, input_shape=(None, 128)),\n",
    "            layers.Reshape((-1, 4, 4, 64)),  # Reshape according to the output shape of encoder\n",
    "            layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same'),\n",
    "            layers.UpSampling3D((2, 2, 2)),\n",
    "            layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same'),\n",
    "            layers.UpSampling3D((2, 2, 2)),\n",
    "            layers.Conv3D(1, (3, 3, 3), activation='sigmoid', padding='same')\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Example usage:\n",
    "model = DynamicLSTMCNNAutoEncoder()\n",
    "model.build((None, None))  # Build the model with dynamic input size\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
